To build:

1. Download and install leiningen http://github.com/technomancy/leiningen
2. $ lein deps
3. $ lein install

core libs for s3, ec2, ssh.

build upon the core is remote repl and cluster capabilities.

in a couple cases, we use an erlang convention of the ! syntax representing "reomote" (on another process) execution.
the first argument to ! in erlang is the pid, wheras in our api, it is an open ssh session or socket.
there is no ! operator or fn, we just use the ! suffix convention to communicate remote execution.

remote shell execution.
(sh! session "tar -xzf repl.tar.gz")

remote repl evaluation.
eval! 
(eval! socket (execute (workflow some-cascading-workflow)))

TODO: add examples for usages.


TODO:
the persistent shell session using jsch ChannelShell is shaky at best, although exec works fine.
eval! may be simpler if we could use LineNumberingPushbackReader see comment in remote_repl.clj
stuff to poll and pull info from hadoop tracker url into repl

SAMPLE:

How to start an ec2 cluster using crane.

;;read in creds "creds.clj"
crane.cluser> (def my-creds (creds "/path/to/creds-dir/"))

{:key "AWS-KEY"
 :secretkey "AWS-SECRET-KEY"
 :private-key-path "/path/to/private-key"
 :key-name "key-name"}

;;read in config "aws.clj"
crane.cluster> (def my-conf (conf "/path/to/conf-dir"))

{:image "ami-"
 :instance-type :m1.large
 :group "ec2-group"
 :instances int
 :instances int
 :creds "/path/to/creds.clj-dir"
 :push ["/file/to/push"
        "/another/file/to/push"]
 :user-data "/path/to/user-data-file"

;;create new Jec2 class
crane.cluster> (def ec (ec2 (creds "/path/to/creds-dir")))

;;start cluster 
(launch-hadoop-cluster ec my-conf)